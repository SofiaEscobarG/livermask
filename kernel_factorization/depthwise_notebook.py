# -*- coding: utf-8 -*-
"""depthwise-notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TKnRjpx6q3ncIDebzsuUUkcY-ZEViHhe
"""

import numpy as np
import scipy as sp
from matplotlib import pyplot as plt

import tensorly as tt

from operator import mul

def reorder(indices, mode):
    """
    Reorders the elements
    Taken from http://jeankossaifi.com/blog/unfolding.html
    """
    indices = list(indices)
    element = indices.pop(mode)
    return ([element] + indices[::-1])

def my_unfold(tensor, mode=0):
    """
    Returns the mode-`mode` unfolding of `tensor`
    Taken from http://jeankossaifi.com/blog/unfolding.html
    """
    return np.transpose(tensor, reorder(range(tensor.ndim), mode)).reshape((tensor.shape[mode], -1))
    

def my_unfold_multi(tensor, modes):
    print(reorder(range(tensor.ndim), modes))
    return np.transpose(tensor, reorder(range(tensor.ndim), modes)).reshape((reduce(mul, [tensor.shape[m] for m in modes], 1), -1))

def fold(unfolded, mode, shape):
    """
    Returns the folded tensor of shape `shape` from the `mode`-mode unfolding `unfolded`.
    Taken from http://jeankossaifi.com/blog/unfolding.html
    """
    unfolded_indices = reorder(range(len(shape)), mode)
    original_shape = [shape[i] for i in unfolded_indices]
    unfolded = unfolded.reshape(original_shape)

    folded_indices = list(range(len(shape)-1, 0, -1))
    folded_indices.insert(mode, 0)
    return np.transpose(unfolded, folded_indices)

def depthwise_factorization(K, dm=1):
    shapeK = K.shape
    dimK   = len(shapeK)
    Kbar   = np.concatenate([K for i in range(dm)], axis=-2)


    k1    = shapeK[0]
    k2    = shapeK[1]
    c_in  = shapeK[-2]*dm
    c_out = shapeK[-1]

    D = tt.tensor(np.random.randn(k1,k2,c_in))
    W = np.random.randn(c_out,c_in)
    I = np.zeros((c_in,c_in,c_in))
    for i in range(c_in):
        I[i,i,i] = 1.0
    I = tt.tensor(I)

    Khat = tt.tenalg.mode_dot( tt.tenalg.inner(D, I, 1), W, -1)
    err  = tt.norm(Khat - Kbar)
    Knorm = tt.norm(K)


    K3 = my_unfold(Kbar, -2)
    K4 = my_unfold(Kbar, -1)
    K3t_vec = (K3.T).flatten(order='F')
    
    n_iter = 0
    n_max  = 50
    err_vec = np.zeros((n_max, 1))
    still_improving = True
    #print(n_iter, err, np.linalg.cond(W))

    while err > 1.e-8 and still_improving and n_iter < n_max:
        err_vec[n_iter] = err

        # fix W, update D
        D3t_vec =  tt.tenalg.kronecker( [np.diag( np.reciprocal(np.diag( W.T @ W)) ) @ tt.tenalg.khatri_rao( [np.identity(c_in), W]).T, np.identity(k1*k2)]) @ K3t_vec
        D = tt.tensor(np.reshape(D3t_vec, D.shape, order='F'))

        # fix D, update W
        D3 = my_unfold(D, -1)
        W = K4 @ tt.tenalg.khatri_rao( [np.identity(c_in), D3.T] ) @ np.diag(np.reciprocal(np.diag(D3 @ D3.T)))
        # rescale W,D so that W has abs-row-sum = 1
        Rvec = np.max(np.abs(W), axis=0)
        W = W @ np.diag(np.reciprocal(Rvec))
        D = tt.tenalg.mode_dot( D, np.diag(Rvec), -1)
        
        
        # Update error
        Khat = tt.tenalg.mode_dot( tt.tenalg.inner(D, I, 1), W, -1)
        err  = tt.norm(Khat - Kbar)/Knorm


        still_improving = err < err_vec[n_iter]
        n_iter += 1
        #print(n_iter, err)

    return D, W, Khat, err_vec, n_iter


#k = 5
#c_in  = 64
#c_out = 64
#dm = 1
#
## Generate test single-channel convolution tensor
#
## test_D = tt.tensor(np.random.randn(k,k,c_in))
#test_D = np.random.randn(k,k,c_in,dm)
#test_W = np.random.randn(c_out,c_in,dm)
#test_K = np.zeros((k,k,c_in,c_out))
#for i1 in range(k):
#    for i2 in range(k):
#        for i3 in range(c_in):
#            for i4 in range(c_out):
##                 for m in range(dm):
##                     test_D[i1,i2,i3,m] = (i1+1)+(i2+1)+(i3+1)+m
##                     test_W[i4,i3,m] = (i3+0.5)**2+(i4+1)+m
#                test_K[i1,i2,i3,i4] = sum([test_D[i1,i2,i3,m]*test_W[i4,i3,m] for m in range(dm)])
#test_K = tt.tensor(test_K)
#test_D = tt.tensor(test_D)
#test_W = tt.tensor(test_W)
#
#D, W, Khat, e, n_iter = depthwise_factorization(test_K, dm=1)
#
#print(Khat.size, Khat.shape)
#print(D.size, D.shape)
#print(W.size, W.shape)
#
#plt.imshow(W)
#plt.colorbar()
#plt.show()
#
#plt.imshow(test_W[...,0])
#plt.colorbar()
#plt.show()
#
#plt.imshow(np.abs(test_W[...,0] - W))
#plt.colorbar()
#plt.show()
#
#np.max(np.abs( my_unfold(test_K, -2) - my_unfold(Khat, -2)[:test_K.shape[-2]]))
#
#print(np.linalg.cond(W))
#print(np.linalg.cond(test_W[...,0]))
#
#plt.figure(figsize=(10,1))
#plt.imshow( my_unfold(K, -2) - my_unfold(Khat, -2)[:K.shape[-2]])
#plt.colorbar()
#plt.show()
#
#plt.hist( np.abs((K - Khat).flatten()), bins=100)
#plt.show()
#
#c_in = 16
#c_out = 16
#K = tt.tensor( np.random.randn(k,k,c_in,c_out))
#
#D, W, Khat, e, n_iter = depthwise_factorization(K, dm=1)







def depthwise_factorization_2(K, dm=1):
    shapeK = K.shape
    dimK   = len(shapeK)
    Kbar   = K

    k1    = shapeK[0]
    k2    = shapeK[1]
    c_in  = shapeK[-2]
    c_out = shapeK[-1]

    D = tt.tensor(np.random.randn(k1,k2,c_in,dm))
    W = np.random.randn(c_out,c_in,dm)
    I = np.zeros((c_in,c_in,c_in))
    for i in range(c_in):
        I[i,i,i] = 1.0
    I = tt.tensor(I)

    
    Khat = tt.tenalg.contract( tt.tenalg.contract(D, 2, I, 2), [2,3], W, [2,1])
    err  = tt.norm(Khat - Kbar)


    K3 = my_unfold(Kbar, -2)
    K4 = my_unfold(Kbar, -1)
    K3t_vec = (K3.T).flatten(order='F')
    
    n_iter = 0
    n_max  = 500
    err_vec = np.zeros((n_max, 1))
    still_improving = True
    print(n_iter, err)

    while err > 1.e-8 and still_improving and n_iter < n_max:
        err_vec[n_iter] = err

        # fix W, update D
        W1 = my_unfold(W, 0)
        D3t_vec =  tt.tenalg.kronecker( [np.diag( np.reciprocal(np.diag( W1.T @ W1)) ) @ tt.tenalg.khatri_rao( [tt.tenalg.kronecker([np.identity(c_in), np.ones((1,dm))]), W1]).T, np.identity(k1*k2)]) @ K3t_vec
        D = tt.tensor(np.reshape(D3t_vec, D.shape, order='F'))

        
        # fix D, update W
#         D3 = my_unfold(D, -1)
#         W = K4 @ tt.tenalg.khatri_rao( [np.identity(c_in), D3.T] ) @ np.diag(np.reciprocal(np.diag(D3 @ D3.T)))
#         # rescale W,D so that W has abs-row-sum = 1
# #         Rvec = np.max(np.abs(W), axis=0)
# #         W = W @ np.diag(np.reciprocal(Rvec))
# #         D = tt.tenalg.mode_dot( D, np.diag(Rvec), -1)
        
        D34 = my_unfold(D, [1,2]) # need to implement
        W1 = tt.tenalg.kronecker([K4, np.ones((1,dm))]) @ tt.tenalg.khatri_rao( [np.identity(c_in*dm), D34.T]) @ np.diag(np.reciprocal(np.diag(D3 @ D3.T)))
        W = my_fold(W1, 0) # need to implement
        
        # Update error
        Khat = tt.tenalg.mode_dot( tt.tenalg.inner(D, I, 1), W, -1)
        err  = tt.norm(Khat - Kbar)


        still_improving = err < err_vec[n_iter]
        n_iter += 1
        print(n_iter, err)

    return D, W, Khat, err_vec, n_iter

#k1 = k
#k2 = k
#
#D = test_D
#W = test_W
#I = np.zeros((c_in,c_in,c_in))
#for i in range(c_in):
#    I[i,i,i] = 1.0
#I = tt.tensor(I)
#Khat = tt.tenalg.contract( tt.tenalg.contract(D, 2, I, 2), [2,3], W, [2,1])
#
#tt.norm(test_K - Khat)
#
#Kbar = Khat
#K3 = my_unfold(Kbar, -2)
#K4 = my_unfold(Kbar, -1)
#K3t_vec = (K3.T).flatten(order='F')
#W1 = my_unfold(W, 0)
#WW = np.diag( np.reciprocal(np.diag( W1.T @ W1)) )
#II = tt.tenalg.kronecker([np.identity(c_in), np.ones((1,dm))])
#IK = tt.tenalg.khatri_rao( [II, W1]).T
#D3t_vec =  tt.tenalg.kronecker( [WW @ IK, np.identity(k1*k2)]) @ K3t_vec
#D = tt.tensor(np.reshape(D3t_vec, D.shape, order='F'))
#
#print(my_unfold_multi(D, [2,3]))